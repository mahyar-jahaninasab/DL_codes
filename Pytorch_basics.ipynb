{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sA2iBcm_cPb"
      },
      "source": [
        "*name* : mahyar jahani nasab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQndOAmiVTO3"
      },
      "source": [
        "# Setup Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H5PzjwH7VTO4"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCtoiSyVVTO8"
      },
      "source": [
        "### Google Colab Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHG0slB6VTO8",
        "outputId": "74230136-a2fe-4842-aead-e630a663fc80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MEmHrgBsgX4"
      },
      "source": [
        "# PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3e_Nux0siHo"
      },
      "source": [
        "[PyTorch](https://pytorch.org/) is an open source machine learning framework. At its core, PyTorch provides a few key features:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdiO3_y-vKQ9"
      },
      "source": [
        "To use PyTorch, we first need to import the `torch` package.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sydFm14itrqq",
        "outputId": "4b1ec655-f0c6-40f6-9b15-ee041b558c50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.1+cu116\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrBSx6hYu8ca"
      },
      "source": [
        "## Tensor Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWagwmXuvIle"
      },
      "source": [
        "### Creating and Accessing tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpwfVUvPu_lF",
        "outputId": "628056c4-c4cf-4c6e-c7ae-deead46319e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is a:\n",
            "tensor([1, 2, 3])\n",
            "type(a):  <class 'torch.Tensor'>\n",
            "rank of a:  1\n",
            "a.shape:  torch.Size([3])\n",
            "\n",
            "a[0]:  tensor(1)\n",
            "type(a[0]):  <class 'torch.Tensor'>\n",
            "type(a[0].item()):  <class 'int'>\n",
            "\n",
            "a after mutating:\n",
            "tensor([ 1, 10,  3])\n"
          ]
        }
      ],
      "source": [
        "# Create a rank 1 tensor from a Python list\n",
        "a = torch.tensor([1, 2, 3])\n",
        "print('Here is a:')\n",
        "print(a)\n",
        "print('type(a): ', type(a))\n",
        "print('rank of a: ', a.dim())\n",
        "print('a.shape: ', a.shape)\n",
        "\n",
        "# Access elements using square brackets\n",
        "print()\n",
        "print('a[0]: ', a[0])\n",
        "print('type(a[0]): ', type(a[0]))\n",
        "print('type(a[0].item()): ', type(a[0].item()))\n",
        "\n",
        "# Mutate elements using square brackets\n",
        "a[1] = 10\n",
        "print()\n",
        "print('a after mutating:')\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZq4zsnLEgXH"
      },
      "source": [
        "The example above shows a one-dimensional tensor; we can similarly create tensors with two or more dimensions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TcvHxpTFUcL",
        "outputId": "1a1dbdb2-6945-4c7f-84a2-947802dbf4c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is b:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 5]])\n",
            "rank of b: 2\n",
            "b.shape:  torch.Size([2, 3])\n",
            "\n",
            "b[0, 1]: tensor(2)\n",
            "b[1, 2]: tensor(5)\n",
            "\n",
            "b after mutating:\n",
            "tensor([[  1,   2,   3],\n",
            "        [  4, 100,   5]])\n"
          ]
        }
      ],
      "source": [
        "# Create a two-dimensional tensor\n",
        "b = torch.tensor([[1, 2, 3], [4, 5, 5]])\n",
        "print('Here is b:')\n",
        "print(b)\n",
        "print('rank of b:', b.dim())\n",
        "print('b.shape: ', b.shape)\n",
        "\n",
        "# Access elements from a multidimensional tensor\n",
        "print()\n",
        "print('b[0, 1]:', b[0, 1])\n",
        "print('b[1, 2]:', b[1, 2])\n",
        "\n",
        "# Mutate elements of a multidimensional tensor\n",
        "b[1, 1] = 100\n",
        "print()\n",
        "print('b after mutating:')\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjCIUzbaVTPs",
        "outputId": "65be7df7-3f46-4eb4-a3a1-73f45d4c375a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is the sample tensor:\n",
            "tensor([[  0.,  10.],\n",
            "        [100.,   0.],\n",
            "        [  0.,   0.]])\n",
            "\n",
            "After mutating:\n",
            "tensor([[ 4., 10.],\n",
            "        [ 5.,  6.],\n",
            "        [ 0.,  0.]])\n",
            "\n",
            "Correct shape:  True\n",
            "x[0, 0] correct:  True\n",
            "x[1, 0] correct:  True\n",
            "x[1, 1] correct:  True\n",
            "\n",
            "Number of elements in x:  6\n",
            "Correctly counted:  True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create a sample tensor\n",
        "x = create_sample_tensor()\n",
        "print('Here is the sample tensor:')\n",
        "print(x)\n",
        "\n",
        "# Mutate the tensor by setting a few elements\n",
        "indices = [(0, 0), (1, 0), (1, 1)]\n",
        "values = [4, 5, 6]\n",
        "mutate_tensor(x, indices, values)\n",
        "print('\\nAfter mutating:')\n",
        "print(x)\n",
        "print('\\nCorrect shape: ', x.shape == (3, 2))\n",
        "print('x[0, 0] correct: ', x[0, 0].item() == 4)\n",
        "print('x[1, 0] correct: ', x[1, 0].item() == 5)\n",
        "print('x[1, 1] correct: ', x[1, 1].item() == 6)\n",
        "\n",
        "# Check the number of elements in the sample tensor\n",
        "num = count_tensor_elements(x)\n",
        "print('\\nNumber of elements in x: ', num)\n",
        "print('Correctly counted: ', num == 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz_VDA3IvP33"
      },
      "source": [
        "### Tensor constructors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoAlslEdwV-k"
      },
      "source": [
        "\n",
        "- [`torch.zeros`](https://pytorch.org/docs/1.1.0/torch.html#torch.zeros): Creates a tensor of all zeros\n",
        "- [`torch.ones`](https://pytorch.org/docs/1.1.0/torch.html#torch.ones): Creates a tensor of all ones\n",
        "- [`torch.rand`](https://pytorch.org/docs/1.1.0/torch.html#torch.rand): Creates a tensor with uniform random numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL6DXGXzxHBA",
        "outputId": "871ea34b-10cf-4dcb-98f6-ac2448374257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor of zeros:\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n",
            "tensor of ones:\n",
            "tensor([[1., 1.]])\n",
            "\n",
            "identity matrix:\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "\n",
            "random tensor:\n",
            "tensor([[0.2847, 0.2951, 0.1298, 0.4984, 0.9979],\n",
            "        [0.0910, 0.2098, 0.4047, 0.4827, 0.6833],\n",
            "        [0.9683, 0.8740, 0.0171, 0.9357, 0.0462],\n",
            "        [0.8734, 0.4581, 0.6211, 0.8356, 0.7395]])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor of all zeros\n",
        "a = torch.zeros(2, 3)\n",
        "print('tensor of zeros:')\n",
        "print(a)\n",
        "\n",
        "# Create a tensor of all ones\n",
        "b = torch.ones(1, 2)\n",
        "print('\\ntensor of ones:')\n",
        "print(b)\n",
        "\n",
        "# Create a 3x3 identity matrix\n",
        "c = torch.eye(3)\n",
        "print('\\nidentity matrix:')\n",
        "print(c)\n",
        "\n",
        "# Tensor of random values\n",
        "d = torch.rand(4, 5)\n",
        "print('\\nrandom tensor:')\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_y7Z5I0NIaA",
        "outputId": "caac8925-91e5-4c77-fa54-c88e2251ce13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x is a tensor: True\n",
            "x has correct shape:  True\n",
            "x is filled with sevens:  True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x = create_tensor_of_pi(4, 5)\n",
        "\n",
        "print('x is a tensor:', torch.is_tensor(x))\n",
        "print('x has correct shape: ', x.shape == (4, 5))\n",
        "print('x is filled with sevens: ', (x == 3.14).all().item() == 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz_hiJD33fu1"
      },
      "source": [
        "### Datatypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG1xBunZ3ixx"
      },
      "source": [
        "PyTorch provides a [large set of numeric datatypes](https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype) that you can use to construct tensors. PyTorch tries to guess a datatype when you create a tensor; functions that construct tensors typically have a `dtype` argument that you can use to explicitly specify a datatype."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vREVDf_n31Qz",
        "outputId": "fe3e2ea7-ef0e-4fa8-c6cb-7323f60b4464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dtype when torch chooses for us:\n",
            "List of integers: torch.int64\n",
            "List of floats: torch.float32\n",
            "Mixed list: torch.float32\n",
            "\n",
            "dtype when we force a datatype:\n",
            "32-bit float:  torch.float32\n",
            "32-bit integer:  torch.int32\n",
            "64-bit integer:  torch.int64\n",
            "\n",
            "torch.ones with different dtypes\n",
            "default dtype: torch.float32\n",
            "16-bit integer: torch.int16\n",
            "8-bit unsigned integer: torch.uint8\n"
          ]
        }
      ],
      "source": [
        "# Let torch choose the datatype\n",
        "x0 = torch.tensor([1, 2])   # List of integers\n",
        "x1 = torch.tensor([1., 2.]) # List of floats\n",
        "x2 = torch.tensor([1., 2])  # Mixed list\n",
        "print('dtype when torch chooses for us:')\n",
        "print('List of integers:', x0.dtype)\n",
        "print('List of floats:', x1.dtype)\n",
        "print('Mixed list:', x2.dtype)\n",
        "\n",
        "# Force a particular datatype\n",
        "y0 = torch.tensor([1, 2], dtype=torch.float32)  # 32-bit float\n",
        "y1 = torch.tensor([1, 2], dtype=torch.int32)    # 32-bit (signed) integer\n",
        "y2 = torch.tensor([1, 2], dtype=torch.int64)    # 64-bit (signed) integer\n",
        "print('\\ndtype when we force a datatype:')\n",
        "print('32-bit float: ', y0.dtype)\n",
        "print('32-bit integer: ', y1.dtype)\n",
        "print('64-bit integer: ', y2.dtype)\n",
        "\n",
        "# Other creation ops also take a dtype argument\n",
        "z0 = torch.ones(1, 2)  # Let torch choose for us\n",
        "z1 = torch.ones(1, 2, dtype=torch.int16) # 16-bit (signed) integer\n",
        "z2 = torch.ones(1, 2, dtype=torch.uint8) # 8-bit (unsigned) integer\n",
        "print('\\ntorch.ones with different dtypes')\n",
        "print('default dtype:', z0.dtype)\n",
        "print('16-bit integer:', z1.dtype)\n",
        "print('8-bit unsigned integer:', z2.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAMpwGsdyHAw",
        "outputId": "68350dfe-eced-482e-849d-751baaa050b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x0: torch.int64\n",
            "x1: torch.float32\n",
            "x2: torch.float64\n",
            "x3: torch.float32\n",
            "x4: torch.float64\n"
          ]
        }
      ],
      "source": [
        "x0 = torch.eye(3, dtype=torch.int64)\n",
        "x1 = x0.float()  # Cast to 32-bit float\n",
        "x2 = x0.double() # Cast to 64-bit float\n",
        "x3 = x0.to(torch.float32) # Alternate way to cast to 32-bit float\n",
        "x4 = x0.to(torch.float64) # Alternate way to cast to 64-bit float\n",
        "print('x0:', x0.dtype)\n",
        "print('x1:', x1.dtype)\n",
        "print('x2:', x2.dtype)\n",
        "print('x3:', x3.dtype)\n",
        "print('x4:', x4.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1APDsx54xV6p",
        "outputId": "01becef1-2c29-45e6-8b7a-769078e3c1f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x0 shape is torch.Size([3, 3]), dtype is torch.float64\n",
            "x1 shape is torch.Size([3, 3]), dtype is torch.float64\n",
            "x2 shape is torch.Size([4, 5]), dtype is torch.float64\n",
            "x3 shape is torch.Size([6, 7]), dtype is torch.float64\n"
          ]
        }
      ],
      "source": [
        "x0 = torch.eye(3, dtype=torch.float64)  # Shape (3, 3), dtype torch.float64\n",
        "x1 = torch.zeros_like(x0)               # Shape (3, 3), dtype torch.float64\n",
        "x2 = x0.new_zeros(4, 5)                 # Shape (4, 5), dtype torch.float64\n",
        "x3 = torch.ones(6, 7).to(x0)            # Shape (6, 7), dtype torch.float64)\n",
        "print('x0 shape is %r, dtype is %r' % (x0.shape, x0.dtype))\n",
        "print('x1 shape is %r, dtype is %r' % (x1.shape, x1.dtype))\n",
        "print('x2 shape is %r, dtype is %r' % (x2.shape, x2.dtype))\n",
        "print('x3 shape is %r, dtype is %r' % (x3.shape, x3.dtype))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qddo6C5Bgwcr",
        "outputId": "576f475a-795c-463e-bfee-79627932541f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct dtype:  True\n",
            "Correct shape:  True\n",
            "Correct values:  True\n",
            "\n",
            "Correct dtype:  True\n",
            "Correct shape:  True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "start = 5\n",
        "stop = 25\n",
        "x = multiples_of_ten(start, stop)\n",
        "print('Correct dtype: ', x.dtype == torch.float64)\n",
        "print('Correct shape: ', x.shape == (2,))\n",
        "print('Correct values: ', x.tolist() == [10, 20])\n",
        "\n",
        "# If there are no multiples of ten in the given range you should return an empty tensor\n",
        "start = 5\n",
        "stop = 7\n",
        "x = multiples_of_ten(start, stop)\n",
        "print('\\nCorrect dtype: ', x.dtype == torch.float64)\n",
        "print('Correct shape: ', x.shape == (0,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlANfnILvX3S"
      },
      "source": [
        "## Tensor indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo-PoTWNvbba"
      },
      "source": [
        "### Slice indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEr5BzdUdCtZ",
        "outputId": "86dcbb74-3c54-4dc8-fde8-b9ecc0a47410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 tensor([ 0, 11, 22, 33, 44, 55, 66])\n",
            "1 tensor([22, 33, 44])\n",
            "2 tensor([22, 33, 44, 55, 66])\n",
            "3 tensor([ 0, 11, 22, 33, 44])\n",
            "4 tensor([ 0, 11, 22, 33, 44, 55, 66])\n",
            "5 tensor([11, 33])\n",
            "6 tensor([ 0, 11, 22, 33, 44, 55])\n",
            "7 tensor([33, 55])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([0, 11, 22, 33, 44, 55, 66])\n",
        "print(0, a)        # (0) Original tensor\n",
        "print(1, a[2:5])   # (1) Elements between index 2 and 5\n",
        "print(2, a[2:])    # (2) Elements after index 2\n",
        "print(3, a[:5])    # (3) Elements before index 5\n",
        "print(4, a[:])     # (4) All elements\n",
        "print(5, a[1:5:2]) # (5) Every second element between indices 1 and 5\n",
        "print(6, a[:-1])   # (6) All but the last element\n",
        "print(7, a[-4::2]) # (7) Every second element, starting from the fourth-last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5fOdjTUyhNf",
        "outputId": "83f67a3f-68b0-4975-c935-0b3a23a1c359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "shape:  torch.Size([3, 4])\n",
            "\n",
            "Single row:\n",
            "tensor([5, 6, 7, 8])\n",
            "tensor([5, 6, 7, 8])\n",
            "shape:  torch.Size([4])\n",
            "\n",
            "Single column:\n",
            "tensor([ 2,  6, 10])\n",
            "shape:  torch.Size([3])\n",
            "\n",
            "First two rows, last two columns:\n",
            "tensor([[2, 3, 4],\n",
            "        [6, 7, 8]])\n",
            "shape:  torch.Size([2, 3])\n",
            "\n",
            "Every other row, middle columns:\n",
            "tensor([[ 2,  3],\n",
            "        [10, 11]])\n",
            "shape:  torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "# Create the following rank 2 tensor with shape (3, 4)\n",
        "# [[ 1  2  3  4]\n",
        "#  [ 5  6  7  8]\n",
        "#  [ 9 10 11 12]]\n",
        "a = torch.tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
        "print('Original tensor:')\n",
        "print(a)\n",
        "print('shape: ', a.shape)\n",
        "\n",
        "# Get row 1, and all columns. \n",
        "print('\\nSingle row:')\n",
        "print(a[1, :])\n",
        "print(a[1])  # Gives the same result; we can omit : for trailing dimensions\n",
        "print('shape: ', a[1].shape)\n",
        "\n",
        "print('\\nSingle column:')\n",
        "print(a[:, 1])\n",
        "print('shape: ', a[:, 1].shape)\n",
        "\n",
        "# Get the first two rows and the last three columns\n",
        "print('\\nFirst two rows, last two columns:')\n",
        "print(a[:2, -3:])\n",
        "print('shape: ', a[:2, -3:].shape)\n",
        "\n",
        "# Get every other row, and columns at index 1 and 2\n",
        "print('\\nEvery other row, middle columns:')\n",
        "print(a[::2, 1:3])\n",
        "print('shape: ', a[::2, 1:3].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1kHcc5jsF-c",
        "outputId": "ef2e13ca-0e32-4b6f-a06c-6f230593a34d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "\n",
            "Two ways of accessing a single row:\n",
            "tensor([5, 6, 7, 8]) torch.Size([4])\n",
            "tensor([[5, 6, 7, 8]]) torch.Size([1, 4])\n",
            "\n",
            "Two ways of accessing a single column:\n",
            "tensor([ 2,  6, 10]) torch.Size([3])\n",
            "tensor([[ 2],\n",
            "        [ 6],\n",
            "        [10]]) torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "# Create the following rank 2 tensor with shape (3, 4)\n",
        "a = torch.tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
        "print('Original tensor')\n",
        "print(a)\n",
        "\n",
        "row_r1 = a[1, :]    # Rank 1 view of the second row of a  \n",
        "row_r2 = a[1:2, :]  # Rank 2 view of the second row of a\n",
        "print('\\nTwo ways of accessing a single row:')\n",
        "print(row_r1, row_r1.shape)\n",
        "print(row_r2, row_r2.shape)\n",
        "\n",
        "# We can make the same distinction when accessing columns::\n",
        "col_r1 = a[:, 1]\n",
        "col_r2 = a[:, 1:2]\n",
        "print('\\nTwo ways of accessing a single column:')\n",
        "print(col_r1, col_r1.shape)\n",
        "print(col_r2, col_r2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXbikYPwyxGA",
        "outputId": "2c26d739-5b0f-483d-a486-950c522008aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before mutating:\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "tensor([2, 3, 4])\n",
            "tensor([2, 3, 4])\n",
            "\n",
            "After mutating:\n",
            "tensor([[ 1, 20, 30,  4],\n",
            "        [ 5,  6,  7,  8]])\n",
            "tensor([20, 30,  4])\n",
            "tensor([ 2,  3, 40])\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor, a slice, and a clone of a slice\n",
        "a = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "b = a[0, 1:]\n",
        "c = a[0, 1:].clone()\n",
        "print('Before mutating:')\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "\n",
        "a[0, 1] = 20  # a[0, 1] and b[0] point to the same element\n",
        "b[1] = 30     # b[1] and a[0, 2] point to the same element\n",
        "c[2] = 40     # c is a clone, so it has its own data\n",
        "print('\\nAfter mutating:')\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "\n",
        "print(a.storage().data_ptr() == c.storage().data_ptr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yKq2mswvqMmw"
      },
      "outputs": [],
      "source": [
        "# We will use this helper function to check your results\n",
        "def check(orig, actual, expected):\n",
        "    if not torch.is_tensor(actual):\n",
        "        return False\n",
        "    expected = torch.tensor(expected)\n",
        "    same_elements = (actual == expected).all().item()\n",
        "    same_storage = (orig.storage().data_ptr() == actual.storage().data_ptr())\n",
        "    return same_elements and same_storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-5UtVXPVTQL",
        "outputId": "1d9056f4-a730-4882-8a04-ac36ebdb24b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "last_row:\n",
            "tensor([11, 12, 13, 14, 15])\n",
            "Correct: True\n",
            "\n",
            "third_col:\n",
            "tensor([[ 3],\n",
            "        [ 8],\n",
            "        [13]])\n",
            "Correct: True\n",
            "\n",
            "first_two_rows_three_cols:\n",
            "tensor([[1, 2, 3],\n",
            "        [6, 7, 8]])\n",
            "Correct: True\n",
            "\n",
            "even_rows_odd_cols:\n",
            "tensor([[ 2,  4],\n",
            "        [12, 14]])\n",
            "Correct: True\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create the following rank 2 tensor of shape (3, 5)\n",
        "# [[ 1  2  3  4  5]\n",
        "#  [ 6  7  8  9 10]\n",
        "#  [11 12 13 14 15]]\n",
        "x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 8, 10], [11, 12, 13, 14, 15]])\n",
        "out = slice_indexing_practice(x)\n",
        "\n",
        "last_row = out[0]\n",
        "print('last_row:')\n",
        "print(last_row)\n",
        "correct = check(x, last_row, [11, 12, 13, 14, 15])\n",
        "print('Correct: %r\\n' % correct)\n",
        "\n",
        "third_col = out[1]\n",
        "print('third_col:')\n",
        "print(third_col)\n",
        "correct = check(x, third_col, [[3], [8], [13]])\n",
        "print('Correct: %r\\n' % correct)\n",
        "\n",
        "first_two_rows_three_cols = out[2]\n",
        "print('first_two_rows_three_cols:')\n",
        "print(first_two_rows_three_cols)\n",
        "correct = check(x, first_two_rows_three_cols, [[1, 2, 3], [6, 7, 8]])\n",
        "print('Correct: %r\\n' % correct)\n",
        "\n",
        "even_rows_odd_cols = out[3]\n",
        "print('even_rows_odd_cols:')\n",
        "print(even_rows_odd_cols)\n",
        "correct = check(x, even_rows_odd_cols, [[2, 4], [12, 14]])\n",
        "print('Correct: %r\\n' % correct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFnky42Rx2I5",
        "outputId": "8767e2cf-f5f3-4606-a7a1-560807ddc009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 1, 2, 3],\n",
            "        [1, 1, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.zeros(2, 4, dtype=torch.int64)\n",
        "a[:, :2] = 1\n",
        "a[:, 2:] = torch.tensor([[2, 3], [4, 5]])\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzXlnFqAVTQQ",
        "outputId": "df9fcfd0-c921-4694-a246-0bb68f82ba7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is x before calling slice_assignment_practice:\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0]])\n",
            "Here is x after calling slice assignment practice:\n",
            "tensor([[0, 1, 2, 2, 2, 2, 0],\n",
            "        [0, 1, 2, 2, 2, 2, 0],\n",
            "        [3, 4, 3, 4, 5, 5, 0],\n",
            "        [3, 4, 3, 4, 5, 5, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0]])\n",
            "Correct:  True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x = torch.zeros(5, 7, dtype=torch.int64)\n",
        "print('Here is x before calling slice_assignment_practice:')\n",
        "print(x)\n",
        "slice_assignment_practice(x)\n",
        "print('Here is x after calling slice assignment practice:')\n",
        "print(x)\n",
        "\n",
        "expected = [\n",
        "    [0, 1, 2, 2, 2, 2, 0],\n",
        "    [0, 1, 2, 2, 2, 2, 0],\n",
        "    [3, 4, 3, 4, 5, 5, 0],\n",
        "    [3, 4, 3, 4, 5, 5, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0],\n",
        "]\n",
        "print('Correct: ', x.tolist() == expected)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y93rPhGveWw"
      },
      "source": [
        "### Integer tensor indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXePPNkjM_SD",
        "outputId": "463ff188-536d-4caf-d66b-0835d17feae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "\n",
            "Reordered rows:\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 1,  2,  3,  4],\n",
            "        [ 9, 10, 11, 12],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 5,  6,  7,  8]])\n",
            "\n",
            "Reordered columns:\n",
            "tensor([[ 4,  3,  2,  1],\n",
            "        [ 8,  7,  6,  5],\n",
            "        [12, 11, 10,  9]])\n"
          ]
        }
      ],
      "source": [
        "# Create the following rank 2 tensor with shape (3, 4)\n",
        "# [[ 1  2  3  4]\n",
        "#  [ 5  6  7  8]\n",
        "#  [ 9 10 11 12]]\n",
        "a = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "print('Original tensor:')\n",
        "print(a)\n",
        "\n",
        "# Create a new tensor of shape (5, 4) by reordering rows from a:\n",
        "# - First two rows same as the first row of a\n",
        "# - Third row is the same as the last row of a\n",
        "# - Fourth and fifth rows are the same as the second row from a\n",
        "idx = [0, 0, 2, 1, 1]  # index arrays can be Python lists of integers\n",
        "print('\\nReordered rows:')\n",
        "print(a[idx])\n",
        "\n",
        "# Create a new tensor of shape (3, 4) by reversing the columns from a\n",
        "idx = torch.tensor([3, 2, 1, 0])  # Index arrays can be int64 torch tensors\n",
        "print('\\nReordered columns:')\n",
        "print(a[:, idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocIR8R5ZSEaP",
        "outputId": "9393b82b-5357-4b46-e223-2fce02bd2c24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "\n",
            "Get the diagonal:\n",
            "tensor([1, 5, 9])\n",
            "\n",
            "After setting the diagonal:\n",
            "tensor([[11,  2,  3],\n",
            "        [ 4, 22,  6],\n",
            "        [ 7,  8, 33]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print('Original tensor:')\n",
        "print(a)\n",
        "\n",
        "idx = [0, 1, 2]\n",
        "print('\\nGet the diagonal:')\n",
        "print(a[idx, idx])\n",
        "\n",
        "# Modify the diagonal\n",
        "a[idx, idx] = torch.tensor([11, 22, 33])\n",
        "print('\\nAfter setting the diagonal:')\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-cr-EqA0vfO"
      },
      "source": [
        "One useful trick with integer array indexing is selecting or mutating one element from each row or column of a matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWA8E8iI0x17",
        "outputId": "b4bb909f-f328-418e-c011-1b283fef8de0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "\n",
            "Select one element from each row:\n",
            "tensor([ 2,  6,  8, 10])\n",
            "\n",
            "After modifying one element from each row:\n",
            "tensor([[ 1,  0,  3],\n",
            "        [ 4,  5,  0],\n",
            "        [ 7,  0,  9],\n",
            "        [ 0, 11, 12]])\n"
          ]
        }
      ],
      "source": [
        "# Create a new tensor from which we will select elements\n",
        "a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
        "print('Original tensor:')\n",
        "print(a)\n",
        "\n",
        "# Take on element from each row of a:\n",
        "# from row 0, take element 1;\n",
        "# from row 1, take element 2;\n",
        "# from row 2, take element 1;\n",
        "# from row 3, take element 0\n",
        "idx0 = torch.arange(a.shape[0])  # Quick way to build [0, 1, 2, 3]\n",
        "idx1 = torch.tensor([1, 2, 1, 0])\n",
        "print('\\nSelect one element from each row:')\n",
        "print(a[idx0, idx1])\n",
        "\n",
        "# Now set each of those elements to zero\n",
        "a[idx0, idx1] = 0\n",
        "print('\\nAfter modifying one element from each row:')\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX05_ov5VTQZ",
        "outputId": "38001ca9-49a5-4e58-ca49-fc021a9850ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is x:\n",
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "\n",
            "Here is shuffle_cols(x):\n",
            "tensor([[ 1,  1,  3,  2],\n",
            "        [ 4,  4,  6,  5],\n",
            "        [ 7,  7,  9,  8],\n",
            "        [10, 10, 12, 11]])\n",
            "Correct: True\n",
            "\n",
            "Here is reverse_rows(x):\n",
            "tensor([[10, 11, 12],\n",
            "        [ 7,  8,  9],\n",
            "        [ 4,  5,  6],\n",
            "        [ 1,  2,  3]])\n",
            "Correct: True\n",
            "\n",
            "Here is take_one_elem_per_col(x):\n",
            "tensor([ 4.,  2., 12.])\n",
            "Correct: True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Build a tensor of shape (4, 3):\n",
        "# [[ 1,  2,  3],\n",
        "#  [ 4,  5,  6],\n",
        "#  [ 7,  8,  9],\n",
        "#  [10, 11, 12]]\n",
        "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
        "print('Here is x:')\n",
        "print(x)\n",
        "\n",
        "y1 = shuffle_cols(x)\n",
        "print('\\nHere is shuffle_cols(x):')\n",
        "print(y1)\n",
        "expected = [[1, 1, 3, 2], [4, 4, 6, 5], [7, 7, 9, 8], [10, 10, 12, 11]]\n",
        "y1_correct = torch.is_tensor(y1) and y1.tolist() == expected\n",
        "print('Correct: %r\\n' % y1_correct)\n",
        "\n",
        "y2 = reverse_rows(x)\n",
        "print('Here is reverse_rows(x):')\n",
        "print(y2)\n",
        "expected = [[10, 11, 12], [7, 8, 9], [4, 5, 6], [1, 2, 3]]\n",
        "y2_correct = torch.is_tensor(y2) and y2.tolist() == expected\n",
        "print('Correct: %r\\n' % y2_correct)\n",
        "\n",
        "y3 = take_one_elem_per_col(x)\n",
        "print('Here is take_one_elem_per_col(x):')\n",
        "print(y3)\n",
        "expected = [4, 2, 12]\n",
        "y3_correct = torch.is_tensor(y3) and y3.tolist() == expected\n",
        "print('Correct: %r' % y3_correct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGt8ZPb_vixw"
      },
      "source": [
        "### Boolean tensor indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Zf7rb82Dkd",
        "outputId": "f8ac5536-112d-46ed-fc67-c8a5247e4261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "Mask tensor:\n",
            "tensor([[False, False],\n",
            "        [False,  True],\n",
            "        [ True,  True]])\n",
            "\n",
            "Selecting elements with the mask:\n",
            "tensor([4, 5, 6])\n",
            "\n",
            "After modifying with a mask:\n",
            "tensor([[0, 0],\n",
            "        [0, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[1,2], [3, 4], [5, 6]])\n",
        "print('Original tensor:')\n",
        "print(a)\n",
        "\n",
        "# Find the elements of a that are bigger than 3. The mask has the same shape as\n",
        "# a, where each element of mask tells whether the corresponding element of a\n",
        "# is greater than three.\n",
        "mask = (a > 3)\n",
        "print('\\nMask tensor:')\n",
        "print(mask)\n",
        "\n",
        "# We can use the mask to construct a rank-1 tensor containing the elements of a\n",
        "# that are selected by the mask\n",
        "print('\\nSelecting elements with the mask:')\n",
        "print(a[mask])\n",
        "\n",
        "# We can also use boolean masks to modify tensors; for example this sets all\n",
        "# elements <= 3 to zero:\n",
        "a[a <= 3] = 0\n",
        "print('\\nAfter modifying with a mask:')\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hkeYXN9d5xh",
        "outputId": "d4a1856d-2749-4444-983e-5fa7c140e95c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct for x0:  True\n",
            "Correct for x1:  True\n",
            "Correct for x2:  True\n"
          ]
        }
      ],
      "source": [
        "# Make a few test cases\n",
        "torch.manual_seed(598)\n",
        "x0 = torch.tensor([[-1, -1, 0], [0, 1, 2], [3, 4, 5]])\n",
        "x1 = torch.tensor([0, 1, 2, 3])\n",
        "x2 = torch.randn(100, 100)\n",
        "print('Correct for x0: ', count_negative_entries(x0) == 2)\n",
        "print('Correct for x1: ', count_negative_entries(x1) == 0)\n",
        "print('Correct for x2: ', count_negative_entries(x2) == 4984)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaT1kuQ37Rsq",
        "outputId": "74a0cef5-cb45-4e35-ad06-76fdb04e1aa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is y0:\n",
            "tensor([[0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 1., 0., 0.]])\n",
            "y0 correct:  True\n",
            "\n",
            "Here is y1:\n",
            "tensor([[0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0.]])\n",
            "y1 correct:  True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def check_one_hot(x, y):\n",
        "    C = y.shape[1]\n",
        "    for i, n in enumerate(x):\n",
        "        if n >= C: return False\n",
        "        for j in range(C):\n",
        "            expected = 1.0 if j == n else 0.0\n",
        "            if y[i, j].item() != expected: return False\n",
        "        return True\n",
        "      \n",
        "x0 = [1, 4, 3, 2]\n",
        "y0 = make_one_hot(x0)\n",
        "print('Here is y0:')\n",
        "print(y0)\n",
        "print('y0 correct: ', check_one_hot(x0, y0))\n",
        "\n",
        "x1 = [1, 3, 5, 7, 6, 2]\n",
        "y1 = make_one_hot(x1)\n",
        "print('\\nHere is y1:')\n",
        "print(y1)\n",
        "print('y1 correct: ', check_one_hot(x1, y1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad-xqELwyqpN"
      },
      "source": [
        "## Reshaping operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql9_eXuU4OG8"
      },
      "source": [
        "### View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw-M7C_61FZK",
        "outputId": "9a9d790d-42ef-437a-8571-2738163bcd54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "shape: torch.Size([2, 4])\n",
            "\n",
            "Flattened tensor:\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
            "shape: torch.Size([8])\n",
            "\n",
            "Row vector:\n",
            "tensor([[1, 2, 3, 4, 5, 6, 7, 8]])\n",
            "shape: torch.Size([1, 8])\n",
            "\n",
            "Column vector:\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5],\n",
            "        [6],\n",
            "        [7],\n",
            "        [8]])\n",
            "shape: torch.Size([8, 1])\n",
            "\n",
            "Rank 3 tensor:\n",
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n",
            "shape: torch.Size([2, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "x0 = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "print('Original tensor:')\n",
        "print(x0)\n",
        "print('shape:', x0.shape)\n",
        "\n",
        "# Flatten x0 into a rank 1 vector of shape (8,)\n",
        "x1 = x0.view(8)\n",
        "print('\\nFlattened tensor:')\n",
        "print(x1)\n",
        "print('shape:', x1.shape)\n",
        "\n",
        "# Convert x1 to a rank 2 \"row vector\" of shape (1, 8)\n",
        "x2 = x1.view(1, 8)\n",
        "print('\\nRow vector:')\n",
        "print(x2)\n",
        "print('shape:', x2.shape)\n",
        "\n",
        "# Convert x1 to a rank 2 \"column vector\" of shape (8, 1)\n",
        "x3 = x1.view(8, 1)\n",
        "print('\\nColumn vector:')\n",
        "print(x3)\n",
        "print('shape:', x3.shape)\n",
        "\n",
        "# Convert x1 to a rank 3 tensor of shape (2, 2, 2):\n",
        "x4 = x1.view(2, 2, 2)\n",
        "print('\\nRank 3 tensor:')\n",
        "print(x4)\n",
        "print('shape:', x4.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNWu-R_J2qFY",
        "outputId": "ea1cf75c-ee3c-478b-8828-25b22d0f9511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x0:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "x0_flat:\n",
            "tensor([1, 2, 3, 4, 5, 6])\n",
            "x0_row:\n",
            "tensor([[1, 2, 3, 4, 5, 6]])\n",
            "\n",
            "x1:\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "x1_flat:\n",
            "tensor([1, 2, 3, 4])\n",
            "x1_row:\n",
            "tensor([[1, 2, 3, 4]])\n"
          ]
        }
      ],
      "source": [
        "# We can reuse these functions for tensors of different shapes\n",
        "def flatten(x):\n",
        "    return x.view(-1)\n",
        "\n",
        "def make_row_vec(x):\n",
        "    return x.view(1, -1)\n",
        "\n",
        "x0 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "x0_flat = flatten(x0)\n",
        "x0_row = make_row_vec(x0)\n",
        "print('x0:')\n",
        "print(x0)\n",
        "print('x0_flat:')\n",
        "print(x0_flat)\n",
        "print('x0_row:')\n",
        "print(x0_row)\n",
        "\n",
        "x1 = torch.tensor([[1, 2], [3, 4]])\n",
        "x1_flat = flatten(x1)\n",
        "x1_row = make_row_vec(x1)\n",
        "print('\\nx1:')\n",
        "print(x1)\n",
        "print('x1_flat:')\n",
        "print(x1_flat)\n",
        "print('x1_row:')\n",
        "print(x1_row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK-ZB5aB2NPq"
      },
      "source": [
        "As its name implies, a tensor returned by `.view()` shares the same data as the input, so changes to one will affect the other and vice-versa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebT99rUo2McN",
        "outputId": "81af3352-3bc0-45bc-9f57-3bbb2a1c7578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x before modifying:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "x_flat before modifying:\n",
            "tensor([1, 2, 3, 4, 5, 6])\n",
            "\n",
            "x after modifying:\n",
            "tensor([[10, 20,  3],\n",
            "        [ 4,  5,  6]])\n",
            "x_flat after modifying:\n",
            "tensor([10, 20,  3,  4,  5,  6])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "x_flat = x.view(-1)\n",
        "print('x before modifying:')\n",
        "print(x)\n",
        "print('x_flat before modifying:')\n",
        "print(x_flat)\n",
        "\n",
        "x[0, 0] = 10   # x[0, 0] and x_flat[0] point to the same data\n",
        "x_flat[1] = 20 # x_flat[1] and x[0, 1] point to the same data\n",
        "\n",
        "print('\\nx after modifying:')\n",
        "print(x)\n",
        "print('x_flat after modifying:')\n",
        "print(x_flat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z150qBob4Wkz"
      },
      "source": [
        "### Swapping axes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_B4NuX6zQm-",
        "outputId": "a4039124-ce2c-41b7-bd70-ff84bef35e5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original matrix:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "Transposing with view DOES NOT WORK!\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "Transposed matrix:\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print('Original matrix:')\n",
        "print(x)\n",
        "print('\\nTransposing with view DOES NOT WORK!')\n",
        "print(x.view(3, 2))\n",
        "print('\\nTransposed matrix:')\n",
        "print(torch.t(x))\n",
        "print(x.t())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN93xo98zn0v"
      },
      "source": [
        "For tensors with more than two dimensions, we can use the function [`torch.transpose`](https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose) to swap arbitrary dimensions, or the [`.permute`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.permute) method to arbitrarily permute dimensions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgN7YB8YzzkA",
        "outputId": "3ba731f1-8727-4b19-81d0-f0599ad33146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[[ 1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8],\n",
            "         [ 9, 10, 11, 12]],\n",
            "\n",
            "        [[13, 14, 15, 16],\n",
            "         [17, 18, 19, 20],\n",
            "         [21, 22, 23, 24]]])\n",
            "shape: torch.Size([2, 3, 4])\n",
            "\n",
            "Swap axes 1 and 2:\n",
            "tensor([[[ 1,  5,  9],\n",
            "         [ 2,  6, 10],\n",
            "         [ 3,  7, 11],\n",
            "         [ 4,  8, 12]],\n",
            "\n",
            "        [[13, 17, 21],\n",
            "         [14, 18, 22],\n",
            "         [15, 19, 23],\n",
            "         [16, 20, 24]]])\n",
            "torch.Size([2, 4, 3])\n",
            "\n",
            "Permute axes\n",
            "tensor([[[ 1, 13],\n",
            "         [ 2, 14],\n",
            "         [ 3, 15],\n",
            "         [ 4, 16]],\n",
            "\n",
            "        [[ 5, 17],\n",
            "         [ 6, 18],\n",
            "         [ 7, 19],\n",
            "         [ 8, 20]],\n",
            "\n",
            "        [[ 9, 21],\n",
            "         [10, 22],\n",
            "         [11, 23],\n",
            "         [12, 24]]])\n",
            "shape: torch.Size([3, 4, 2])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor of shape (2, 3, 4)\n",
        "x0 = torch.tensor([\n",
        "     [[1,  2,  3,  4],\n",
        "      [5,  6,  7,  8],\n",
        "      [9, 10, 11, 12]],\n",
        "     [[13, 14, 15, 16],\n",
        "      [17, 18, 19, 20],\n",
        "      [21, 22, 23, 24]]])\n",
        "print('Original tensor:')\n",
        "print(x0)\n",
        "print('shape:', x0.shape)\n",
        "\n",
        "# Swap axes 1 and 2; shape is (2, 4, 3)\n",
        "x1 = x0.transpose(1, 2)\n",
        "print('\\nSwap axes 1 and 2:')\n",
        "print(x1)\n",
        "print(x1.shape)\n",
        "\n",
        "# Permute axes; the argument (1, 2, 0) means:\n",
        "# - Make the old dimension 1 appear at dimension 0;\n",
        "# - Make the old dimension 2 appear at dimension 1;\n",
        "# - Make the old dimension 0 appear at dimension 2\n",
        "# This results in a tensor of shape (3, 4, 2)\n",
        "x2 = x0.permute(1, 2, 0)\n",
        "print('\\nPermute axes')\n",
        "print(x2)\n",
        "print('shape:', x2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4SJCVbf-bZ0"
      },
      "source": [
        "### Contiguous tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGC6NERq_CT9",
        "outputId": "e1930e5a-d697-49db-ec8d-aa828466e5c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'RuntimeError'> view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
            "x1 shape:  torch.Size([8, 3])\n",
            "x2 shape:  torch.Size([8, 3])\n"
          ]
        }
      ],
      "source": [
        "x0 = torch.randn(2, 3, 4)\n",
        "\n",
        "try:\n",
        "  # This sequence of reshape operations will crash\n",
        "  x1 = x0.transpose(1, 2).view(8, 3)\n",
        "except RuntimeError as e:\n",
        "  print(type(e), e)\n",
        "  \n",
        "# We can solve the problem using either .contiguous() or .reshape()\n",
        "x1 = x0.transpose(1, 2).contiguous().view(8, 3)\n",
        "x2 = x0.transpose(1, 2).reshape(8, 3)\n",
        "print('x1 shape: ', x1.shape)\n",
        "print('x2 shape: ', x2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8reAZGzFVTQ3",
        "outputId": "7b8b69d2-c910-4215-8d02-7a0e79528182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is x:\n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23])\n",
            "Here is y:\n",
            "tensor([[ 0,  1,  2,  3, 12, 13, 14, 15],\n",
            "        [ 4,  5,  6,  7, 16, 17, 18, 19],\n",
            "        [ 8,  9, 10, 11, 20, 21, 22, 23]])\n",
            "Correct: True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x = torch.arange(24)\n",
        "print('Here is x:')\n",
        "print(x)\n",
        "y = reshape_practice(x)\n",
        "print('Here is y:')\n",
        "print(y)\n",
        "\n",
        "expected = [\n",
        "    [0, 1,  2,  3, 12, 13, 14, 15],\n",
        "    [4, 5,  6,  7, 16, 17, 18, 19],\n",
        "    [8, 9, 10, 11, 20, 21, 22, 23]]\n",
        "print('Correct:', y.tolist() == expected)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgcdvD1evxTQ"
      },
      "source": [
        "## Tensor operations\n",
        "So far we have seen how to construct, access, and reshape tensors. But one of the most important reasons to use tensors is for performing computation! PyTorch provides many different operations to perform computations on tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BCVlPHZ4_Qz"
      },
      "source": [
        "### Elementwise operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2wbN18E5CKI"
      },
      "source": [
        "Basic mathematical functions operate elementwise on tensors, and are available as operator overloads, as functions in the `torch` module, and as instance methods on torch objects; all produce the same results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrMkbk535KRZ",
        "outputId": "bc339f75-bb16-4fa0-b6b6-f28337585133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elementwise sum:\n",
            "tensor([[ 6.,  8., 10., 12.]])\n",
            "tensor([[ 6.,  8., 10., 12.]])\n",
            "tensor([[ 6.,  8., 10., 12.]])\n",
            "\n",
            "Elementwise difference:\n",
            "tensor([[-4., -4., -4., -4.]])\n",
            "tensor([[-4., -4., -4., -4.]])\n",
            "tensor([[-4., -4., -4., -4.]])\n",
            "\n",
            "Elementwise product:\n",
            "tensor([[ 5., 12., 21., 32.]])\n",
            "tensor([[ 5., 12., 21., 32.]])\n",
            "tensor([[ 5., 12., 21., 32.]])\n",
            "\n",
            "Elementwise division\n",
            "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
            "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
            "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
            "\n",
            "Elementwise power\n",
            "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n",
            "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n",
            "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3, 4]], dtype=torch.float32)\n",
        "y = torch.tensor([[5, 6, 7, 8]], dtype=torch.float32)\n",
        "\n",
        "# Elementwise sum; all give the same result\n",
        "print('Elementwise sum:')\n",
        "print(x + y)\n",
        "print(torch.add(x, y))\n",
        "print(x.add(y))\n",
        "\n",
        "# Elementwise difference\n",
        "print('\\nElementwise difference:')\n",
        "print(x - y)\n",
        "print(torch.sub(x, y))\n",
        "print(x.sub(y))\n",
        "\n",
        "# Elementwise product\n",
        "print('\\nElementwise product:')\n",
        "print(x * y)\n",
        "print(torch.mul(x, y))\n",
        "print(x.mul(y))\n",
        "\n",
        "# Elementwise division\n",
        "print('\\nElementwise division')\n",
        "print(x / y)\n",
        "print(torch.div(x, y))\n",
        "print(x.div(y))\n",
        "\n",
        "# Elementwise power\n",
        "print('\\nElementwise power')\n",
        "print(x ** y)\n",
        "print(torch.pow(x, y))\n",
        "print(x.pow(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s87mjsnG58vR",
        "outputId": "13247033-5272-4dda-a057-ba229ec5ac27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Square root:\n",
            "tensor([[1.0000, 1.4142, 1.7321, 2.0000]])\n",
            "tensor([[1.0000, 1.4142, 1.7321, 2.0000]])\n",
            "\n",
            "Trig functions:\n",
            "tensor([[ 0.8415,  0.9093,  0.1411, -0.7568]])\n",
            "tensor([[ 0.8415,  0.9093,  0.1411, -0.7568]])\n",
            "tensor([[ 0.5403, -0.4161, -0.9900, -0.6536]])\n",
            "tensor([[ 0.5403, -0.4161, -0.9900, -0.6536]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3, 4]], dtype=torch.float32)\n",
        "\n",
        "print('Square root:')\n",
        "print(torch.sqrt(x))\n",
        "print(x.sqrt())\n",
        "\n",
        "print('\\nTrig functions:')\n",
        "print(torch.sin(x))\n",
        "print(x.sin())\n",
        "print(torch.cos(x))\n",
        "print(x.cos())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDyH9USAuyZ-"
      },
      "source": [
        "### Reduction operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlmsYJWUE2r3",
        "outputId": "64d40cf2-ec94-4ea7-ae0c-95a26b81def4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "\n",
            "Sum over entire tensor:\n",
            "tensor(21.)\n",
            "tensor(21.)\n",
            "\n",
            "Sum of each row:\n",
            "tensor([5., 7., 9.])\n",
            "tensor([5., 7., 9.])\n",
            "\n",
            "Sum of each column:\n",
            "tensor([ 6., 15.])\n",
            "tensor([ 6., 15.])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3], \n",
        "                  [4, 5, 6]], dtype=torch.float32)\n",
        "print('Original tensor:')\n",
        "print(x)\n",
        "\n",
        "print('\\nSum over entire tensor:')\n",
        "print(torch.sum(x))\n",
        "print(x.sum())\n",
        "\n",
        "# We can sum over each row:\n",
        "print('\\nSum of each row:')\n",
        "print(torch.sum(x, dim=0))\n",
        "print(x.sum(dim=0))\n",
        "\n",
        "# Sum over each column:\n",
        "print('\\nSum of each column:')\n",
        "print(torch.sum(x, dim=1))\n",
        "print(x.sum(dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFD7aT54H4ik",
        "outputId": "d9493099-4675-4eb2-bfc9-b395abf7ac60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[2., 4., 3., 5.],\n",
            "        [3., 3., 5., 2.]]) torch.Size([2, 4])\n",
            "\n",
            "Overall minimum:  tensor(2.)\n",
            "\n",
            "Minimum along each column:\n",
            "values: tensor([2., 3., 3., 2.])\n",
            "idxs: tensor([0, 1, 0, 1])\n",
            "\n",
            "Minimum along each row:\n",
            "values: tensor([2., 2.])\n",
            "idxs: tensor([0, 3])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[2, 4, 3, 5], [3, 3, 5, 2]], dtype=torch.float32)\n",
        "print('Original tensor:')\n",
        "print(x, x.shape)\n",
        "\n",
        "# Finding the overall minimum only returns a single value\n",
        "print('\\nOverall minimum: ', x.min())\n",
        "\n",
        "# Compute the minimum along each column; we get both the value and location:\n",
        "# The minimum of the first column is 2, and it appears at index 0;\n",
        "# the minimum of the second column is 3 and it appears at index 1; etc\n",
        "col_min_vals, col_min_idxs = x.min(dim=0)\n",
        "print('\\nMinimum along each column:')\n",
        "print('values:', col_min_vals)\n",
        "print('idxs:', col_min_idxs)\n",
        "\n",
        "# Compute the minimum along each row; we get both the value and the minimum\n",
        "row_min_vals, row_min_idxs = x.min(dim=1)\n",
        "print('\\nMinimum along each row:')\n",
        "print('values:', row_min_vals)\n",
        "print('idxs:', row_min_idxs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjcAveyJFqm7",
        "outputId": "ac640aaf-1206-40d3-e4b2-e0834375c8b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 10, 3, 64, 64])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 3, 64])\n",
            "torch.Size([128, 1, 64])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor of shape (128, 10, 3, 64, 64)\n",
        "x = torch.randn(128, 10, 3, 64, 64)\n",
        "print(x.shape)\n",
        "\n",
        "# Take the mean over dimension 1; shape is now (128, 3, 64, 64)\n",
        "x = x.mean(dim=1)\n",
        "print(x.shape)\n",
        "\n",
        "# Take the sum over dimension 2; shape is now (128, 3, 64)\n",
        "x = x.sum(dim=2)\n",
        "print(x.shape)\n",
        "\n",
        "# Take the mean over dimension 1, but keep the dimension from being eliminated\n",
        "# by passing keepdim=True; shape is now (128, 1, 64)\n",
        "x = x.mean(dim=1, keepdim=True)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaJzt-Y62blF",
        "outputId": "5c2bf734-6e5e-4081-ff6a-0a3d6676a294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is x0:\n",
            "tensor([[10, 20, 30],\n",
            "        [ 2,  5,  1]])\n",
            "Here is y0:\n",
            "tensor([[ 0, 20, 30],\n",
            "        [ 2,  5,  0]])\n",
            "y0 correct:  True\n",
            "\n",
            "Here is x1:\n",
            "tensor([[ 2,  5, 10, -1],\n",
            "        [ 1,  3,  2,  4],\n",
            "        [ 5,  6,  2, 10]])\n",
            "Here is y1:\n",
            "tensor([[ 2,  5, 10,  0],\n",
            "        [ 0,  3,  2,  4],\n",
            "        [ 5,  6,  0, 10]])\n",
            "y1 correct:  True\n"
          ]
        }
      ],
      "source": [
        "x0 = torch.tensor([[10, 20, 30], [2, 5, 1]])\n",
        "print('Here is x0:')\n",
        "print(x0)\n",
        "y0 = zero_row_min(x0)\n",
        "print('Here is y0:')\n",
        "print(y0)\n",
        "expected = [[0, 20, 30], [2, 5, 0]]\n",
        "y0_correct = torch.is_tensor(y0) and y0.tolist() == expected\n",
        "print('y0 correct: ', y0_correct)\n",
        "\n",
        "x1 = torch.tensor([[2, 5, 10, -1], [1, 3, 2, 4], [5, 6, 2, 10]])\n",
        "print('\\nHere is x1:')\n",
        "print(x1)\n",
        "y1 = zero_row_min(x1)\n",
        "print('Here is y1:')\n",
        "print(y1)\n",
        "expected = [[2, 5, 10, 0], [0, 3, 2, 4], [5, 6, 0, 10]]\n",
        "y1_correct = torch.is_tensor(y1) and y1.tolist() == expected\n",
        "print('y1 correct: ', y1_correct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRyLyXU2u29N"
      },
      "source": [
        "### Matrix operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRUYW2as6ZCh",
        "outputId": "c2d8607a-3491-4025-d13c-241cc366dfab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dot products:\n",
            "tensor(219.)\n",
            "tensor(219.)\n",
            "1D tensors expected, but got 2D and 2D tensors\n",
            "\n",
            "Matrix-matrix product:\n",
            "tensor([[19., 22.],\n",
            "        [43., 50.]])\n",
            "tensor([[19., 22.],\n",
            "        [43., 50.]])\n"
          ]
        }
      ],
      "source": [
        "v = torch.tensor([9,10], dtype=torch.float32)\n",
        "w = torch.tensor([11, 12], dtype=torch.float32)\n",
        "\n",
        "# Inner product of vectors\n",
        "print('Dot products:')\n",
        "print(torch.dot(v, w))\n",
        "print(v.dot(w))\n",
        "\n",
        "# dot only works for vectors -- it will give an error for tensors of rank > 1\n",
        "x = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
        "y = torch.tensor([[5,6],[7,8]], dtype=torch.float32)\n",
        "try:\n",
        "  print(x.dot(y))\n",
        "except RuntimeError as e:\n",
        "  print(e)\n",
        "  \n",
        "# Instead we use mm for matrix-matrix products:\n",
        "print('\\nMatrix-matrix product:')\n",
        "print(torch.mm(x, y))\n",
        "print(x.mm(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqEzcnHkdRYA",
        "outputId": "315c550d-ddb2-4653-ef03-b53853561925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is x (rank 2):\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "\n",
            "Here is v (rank 1):\n",
            "tensor([ 9., 10.])\n",
            "\n",
            "Matrix-vector product with torch.mv (rank 1 output)\n",
            "tensor([29., 67.])\n",
            "tensor([29., 67.])\n",
            "\n",
            "Matrix-vector product with torch.mm (rank 2 output)\n",
            "tensor([[29.],\n",
            "        [67.]])\n",
            "tensor([[29.],\n",
            "        [67.]])\n",
            "\n",
            "Matrix-vector product with torch.matmul (rank 1 output)\n",
            "tensor([29., 67.])\n",
            "tensor([29., 67.])\n"
          ]
        }
      ],
      "source": [
        "print('Here is x (rank 2):')\n",
        "print(x)\n",
        "print('\\nHere is v (rank 1):')\n",
        "print(v)\n",
        "\n",
        "# Matrix-vector multiply with torch.mv produces a rank-1 output\n",
        "print('\\nMatrix-vector product with torch.mv (rank 1 output)')\n",
        "print(torch.mv(x, v))\n",
        "print(x.mv(v))\n",
        "\n",
        "# We can reshape the vector to have rank 2 and use torch.mm to perform\n",
        "# matrix-vector products, but the result will have rank 2\n",
        "print('\\nMatrix-vector product with torch.mm (rank 2 output)')\n",
        "print(torch.mm(x, v.view(2, 1)))\n",
        "print(x.mm(v.view(2, 1)))\n",
        "\n",
        "print('\\nMatrix-vector product with torch.matmul (rank 1 output)')\n",
        "print(torch.matmul(x, v))\n",
        "print(x.matmul(v))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZD1VQHKVTRQ",
        "outputId": "45cf4f06-8de3-4e9b-b83f-0232b108db93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z1 difference:  0.0\n",
            "z1 difference within tolerance:  True\n",
            "\n",
            "z2 difference:  2.384185791015625e-07\n",
            "z2 difference within tolerance:  True\n"
          ]
        }
      ],
      "source": [
        "B, N, M, P = 2, 3, 5, 4\n",
        "x = torch.randn(B, N, M)\n",
        "y = torch.randn(B, M, P)\n",
        "z_expected = torch.stack([x[0] @ y[0], x[1] @ y[1]])\n",
        "\n",
        "# The two may not return exactly the same result; different linear algebra\n",
        "# routines often return slightly different results due to the fact that\n",
        "# floating-point math is non-exact and non-associative.\n",
        "z1 = batched_matrix_multiply(x, y, use_loop=True)\n",
        "z1_diff = (z1 - z_expected).abs().max().item()\n",
        "print('z1 difference: ', z1_diff)\n",
        "print('z1 difference within tolerance: ', z1_diff < 1e-6)\n",
        "\n",
        "z2 = batched_matrix_multiply(x, y, use_loop=False)\n",
        "z2_diff = (z2 - z_expected).abs().max().item()\n",
        "print('\\nz2 difference: ', z2_diff)\n",
        "print('z2 difference within tolerance: ', z2_diff < 1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "a-acTIOpVTRR",
        "outputId": "ee9e945a-922d-48e7-80d8-2877b36a4651"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "N, M, P = 100, 100, 100\n",
        "loop_times = []\n",
        "no_loop_times = []\n",
        "Bs = list(range(5, 100, 5))\n",
        "num_trials = 20\n",
        "for B in Bs:\n",
        "    loop_trials = []\n",
        "    no_loop_trials = []\n",
        "    for trial in range(num_trials):\n",
        "        x = torch.randn(B, N, M)\n",
        "        y = torch.randn(B, M, P)\n",
        "        t0 = time.time()\n",
        "        z1 = batched_matrix_multiply(x, y, use_loop=True)\n",
        "        t1 = time.time()\n",
        "        z2 = batched_matrix_multiply(x, y, use_loop=False)\n",
        "        t2 = time.time()\n",
        "        loop_trials.append(t1 - t0)\n",
        "        no_loop_trials.append(t2 - t1)\n",
        "    loop_mean = torch.tensor(loop_trials).mean().item()\n",
        "    no_loop_mean = torch.tensor(no_loop_trials).mean().item()\n",
        "    loop_times.append(loop_mean)\n",
        "    no_loop_times.append(no_loop_mean)\n",
        "    \n",
        "plt.plot(Bs, loop_times, 'o-', label='use_loop=True')\n",
        "plt.plot(Bs, no_loop_times, 'o-', label='use_loop=False')\n",
        "plt.xlabel('Batch size B')\n",
        "plt.ylabel('Runtime (s)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UISn2pcf9QjY"
      },
      "source": [
        "## Broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF0Dhzlu9fef",
        "outputId": "e5d3e1c6-24c9-41e6-d227-df3b89fd121d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2,  2,  4],\n",
            "        [ 5,  5,  7],\n",
            "        [ 8,  8, 10],\n",
            "        [11, 11, 13]])\n"
          ]
        }
      ],
      "source": [
        "# We will add the vector v to each row of the matrix x,\n",
        "# storing the result in the matrix y\n",
        "x = torch.tensor([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])\n",
        "v = torch.tensor([1, 0, 1])\n",
        "y = torch.zeros_like(x)   # Create an empty matrix with the same shape as x\n",
        "\n",
        "# Add the vector v to each row of the matrix x with an explicit loop\n",
        "for i in range(4):\n",
        "    y[i, :] = x[i, :] + v\n",
        "\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2_5cKeu94c2",
        "outputId": "964eb71e-93fb-4b99-af77-029754339153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 0, 1],\n",
            "        [1, 0, 1],\n",
            "        [1, 0, 1],\n",
            "        [1, 0, 1]])\n"
          ]
        }
      ],
      "source": [
        "vv = v.repeat((4, 1))  # Stack 4 copies of v on top of each other\n",
        "print(vv)              # Prints \"[[1 0 1]\n",
        "                       #          [1 0 1]\n",
        "                       #          [1 0 1]\n",
        "                       #          [1 0 1]]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KiRj23p-QIs",
        "outputId": "e19ee829-c6f3-486d-99eb-28ed94f25923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2,  2,  4],\n",
            "        [ 5,  5,  7],\n",
            "        [ 8,  8, 10],\n",
            "        [11, 11, 13]])\n"
          ]
        }
      ],
      "source": [
        "y = x + vv  # Add x and vv elementwise\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jIiZc-ABBnt",
        "outputId": "aebd98a7-362b-4cc3-c305-11a37463d30a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2,  2,  4],\n",
            "        [ 5,  5,  7],\n",
            "        [ 8,  8, 10],\n",
            "        [11, 11, 13]])\n"
          ]
        }
      ],
      "source": [
        "# We will add the vector v to each row of the matrix x,\n",
        "# storing the result in the matrix y\n",
        "x = torch.tensor([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])\n",
        "v = torch.tensor([1, 0, 1])\n",
        "y = x + v  # Add v to each row of x using broadcasting\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIlIBao3VTRc",
        "outputId": "6b29b478-25f1-41f4-eb13-020c896ae82c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is x (before broadcasting):\n",
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "x.shape:  torch.Size([4, 3])\n",
            "\n",
            "Here is v (before broadcasting):\n",
            "tensor([1, 0, 1])\n",
            "v.shape:  torch.Size([3])\n",
            "Here is xx (after) broadcasting):\n",
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "xx.shape:  torch.Size([4, 3])\n",
            "\n",
            "Here is vv (after broadcasting):\n",
            "tensor([[1, 0, 1],\n",
            "        [1, 0, 1],\n",
            "        [1, 0, 1],\n",
            "        [1, 0, 1]])\n",
            "vv.shape:  torch.Size([4, 3])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
        "v = torch.tensor([1, 0, 1])\n",
        "print('Here is x (before broadcasting):')\n",
        "print(x)\n",
        "print('x.shape: ', x.shape)\n",
        "print('\\nHere is v (before broadcasting):')\n",
        "print(v)\n",
        "print('v.shape: ', v.shape)\n",
        "\n",
        "xx, vv = torch.broadcast_tensors(x, v)\n",
        "print('Here is xx (after) broadcasting):')\n",
        "print(xx)\n",
        "print('xx.shape: ', x.shape)\n",
        "print('\\nHere is vv (after broadcasting):')\n",
        "print(vv)\n",
        "print('vv.shape: ', vv.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W-k7-hpCwlT",
        "outputId": "4eacc76d-ed57-49b0-ed01-79034c799ad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 4,  5],\n",
            "        [ 8, 10],\n",
            "        [12, 15]])\n"
          ]
        }
      ],
      "source": [
        "# Compute outer product of vectors\n",
        "v = torch.tensor([1, 2, 3])  # v has shape (3,)\n",
        "w = torch.tensor([4, 5])     # w has shape (2,)\n",
        "# To compute an outer product, we first reshape v to be a column\n",
        "# vector of shape (3, 1); we can then broadcast it against w to yield\n",
        "# an output of shape (3, 2), which is the outer product of v and w:\n",
        "print(v.view(3, 1) * w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a9EcX20moP_"
      },
      "source": [
        "We can add a vector to each row of a matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bhmBiwcDF1B",
        "outputId": "818ead26-0a53-4e2e-8208-6af4363d327a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is the matrix:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "Here is the vector:\n",
            "tensor([1, 2, 3])\n",
            "\n",
            "Add the vector to each row of the matrix:\n",
            "tensor([[2, 4, 6],\n",
            "        [5, 7, 9]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # x has shape (2, 3)\n",
        "v = torch.tensor([1, 2, 3])               # v has shape (3,)\n",
        "print('Here is the matrix:')\n",
        "print(x)\n",
        "print('\\nHere is the vector:')\n",
        "print(v)\n",
        "\n",
        "# x has shape (2, 3) and v has shape (3,) so they broadcast to (2, 3),\n",
        "# giving the following matrix:\n",
        "print('\\nAdd the vector to each row of the matrix:')\n",
        "print(x + v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDTFKACqDK22",
        "outputId": "e6c8dcec-87b3-4200-ed86-0bb388c51bf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is the matrix:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "Here is the vector:\n",
            "tensor([4, 5])\n",
            "\n",
            "Add the vector to each column of the matrix:\n",
            "tensor([[ 5,  6,  7],\n",
            "        [ 9, 10, 11]])\n",
            "tensor([[ 5,  6,  7],\n",
            "        [ 9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # x has shape (2, 3)\n",
        "w = torch.tensor([4, 5])                  # w has shape (2,)\n",
        "print('Here is the matrix:')\n",
        "print(x)\n",
        "print('\\nHere is the vector:')\n",
        "print(w)\n",
        "\n",
        "# x has shape (2, 3) and w has shape (2,). We reshape w to (2, 1);\n",
        "# then when we add the two the result broadcasts to (2, 3):\n",
        "print('\\nAdd the vector to each column of the matrix:')\n",
        "print(x + w.view(-1, 1))\n",
        "\n",
        "# Another solution is the following:\n",
        "# 1. Transpose x so it has shape (3, 2)\n",
        "# 2. Since w has shape (2,), adding will broadcast to (3, 2)\n",
        "# 3. Transpose the result, resulting in a shape (2, 3)\n",
        "print((x.t() + w).t())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9717YmBBpBfr"
      },
      "source": [
        "Multiply a tensor by a set of constants:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UjWDp_XDc_-",
        "outputId": "83e39d42-7218-4d04-f50d-f0726f9e501c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is the matrix:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "Here is the vector:\n",
            "tensor([  1,  10,  11, 100])\n",
            "\n",
            "Multiply x by a set of constants:\n",
            "tensor([[[  1,   2,   3],\n",
            "         [  4,   5,   6]],\n",
            "\n",
            "        [[ 10,  20,  30],\n",
            "         [ 40,  50,  60]],\n",
            "\n",
            "        [[ 11,  22,  33],\n",
            "         [ 44,  55,  66]],\n",
            "\n",
            "        [[100, 200, 300],\n",
            "         [400, 500, 600]]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # x has shape (2, 3)\n",
        "c = torch.tensor([1, 10, 11, 100])        # c has shape (4)\n",
        "print('Here is the matrix:')\n",
        "print(x)\n",
        "print('\\nHere is the vector:')\n",
        "print(c)\n",
        "\n",
        "# We do the following:\n",
        "# 1. Reshape c from (4,) to (4, 1, 1)\n",
        "# 2. x has shape (2, 3). Since they have different ranks, when we multiply the\n",
        "#    two, x behaves as if its shape were (1, 2, 3)\n",
        "# 3. The result of the broadcast multiplication between tensor of shape\n",
        "#    (4, 1, 1) and (1, 2, 3) has shape (4, 2, 3)\n",
        "# 4. The result y has shape (4, 2, 3), and y[i] (shape (2, 3)) is equal to\n",
        "#    c[i] * x\n",
        "y = c.view(-1, 1, 1) * x\n",
        "print('\\nMultiply x by a set of constants:')\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVh1DMqMr3zl",
        "outputId": "4354be37-8c48-4916-cd90-9d4531be86b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is x:\n",
            "tensor([[  0.,  30., 600.],\n",
            "        [  1.,  10., 200.],\n",
            "        [ -1.,  20., 400.]])\n",
            "Here is y:\n",
            "tensor([[ 0.,  1.,  1.],\n",
            "        [ 1., -1., -1.],\n",
            "        [-1.,  0.,  0.]])\n",
            "y correct:  True\n",
            "x unchanged:  True\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[0., 30., 600.], [1., 10., 200.], [-1., 20., 400.]])\n",
        "y = normalize_columns(x)\n",
        "print('Here is x:')\n",
        "print(x)\n",
        "print('Here is y:')\n",
        "print(y)\n",
        "\n",
        "x_expected = [[0., 30., 600.], [1., 10., 200.], [-1., 20., 400.]]\n",
        "y_expected = [[0., 1., 1.], [1., -1., -1.], [-1., 0., 0.]]\n",
        "y_correct = y.tolist() == y_expected\n",
        "x_correct = x.tolist() == x_expected\n",
        "print('y correct: ', y_correct)\n",
        "print('x unchanged: ', x_correct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnwGzmU9VTRp",
        "outputId": "747cf8a9-d84a-442d-dfd1-f0837cd2e4ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Out-of-place addition:\n",
            "Before addition:\n",
            "x:  tensor([1, 2, 3])\n",
            "y:  tensor([3, 4, 5])\n",
            "\n",
            "After addition (x and y unchanged):\n",
            "x:  tensor([1, 2, 3])\n",
            "y:  tensor([3, 4, 5])\n",
            "z:  tensor([4, 6, 8])\n",
            "z is x:  False\n",
            "z is y:  False\n",
            "\n",
            "\n",
            "In-place Addition:\n",
            "Before addition:\n",
            "x:  tensor([1, 2, 3])\n",
            "y:  tensor([3, 4, 5])\n",
            "\n",
            "After addition (x is modified):\n",
            "x:  tensor([4, 6, 8])\n",
            "y:  tensor([3, 4, 5])\n",
            "z:  tensor([4, 6, 8])\n",
            "z is x:  False\n",
            "z is y:  False\n"
          ]
        }
      ],
      "source": [
        "# Out-of-place addition creates and returns a new tensor without modifying the inputs:\n",
        "x = torch.tensor([1, 2, 3])\n",
        "y = torch.tensor([3, 4, 5])\n",
        "print('Out-of-place addition:')\n",
        "print('Before addition:')\n",
        "print('x: ', x)\n",
        "print('y: ', y)\n",
        "z = x.add(y)  # Same as z = x + y or z = torch.add(x, y)\n",
        "print('\\nAfter addition (x and y unchanged):')\n",
        "print('x: ', x)\n",
        "print('y: ', y)\n",
        "print('z: ', z)\n",
        "print('z is x: ', z is x)\n",
        "print('z is y: ', z is y)\n",
        "\n",
        "# In-place addition modifies the input tensor:\n",
        "print('\\n\\nIn-place Addition:')\n",
        "print('Before addition:')\n",
        "print('x: ', x)\n",
        "print('y: ', y)\n",
        "x.add_(y)  # Same as x += y or torch.add(x, y, out=x)\n",
        "print('\\nAfter addition (x is modified):')\n",
        "print('x: ', x)\n",
        "print('y: ', y)\n",
        "print('z: ', z)\n",
        "print('z is x: ', z is x)\n",
        "print('z is y: ', z is y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN6FfqU9wFeG"
      },
      "source": [
        "## Running on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RkoFEVVKWlW",
        "outputId": "d51cbd52-9961-4ac0-e52f-a8fe9d3c27f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch can use GPUs!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available:\n",
        "  print('PyTorch can use GPUs!')\n",
        "else:\n",
        "  print('PyTorch cannot use GPUs.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D03s614dMCvy",
        "outputId": "7755fe1f-1de8-41ed-b077-1bc97f15f558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x0 device: cpu\n",
            "x1 device: cuda:0\n",
            "x2 device: cuda:0\n",
            "x3 device: cpu\n",
            "x4 device: cpu\n",
            "y device / dtype: cuda:0 torch.float64\n",
            "x5 device / dtype: cuda:0 torch.float64\n"
          ]
        }
      ],
      "source": [
        "# Construct a tensor on the CPU\n",
        "x0 = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "print('x0 device:', x0.device)\n",
        "\n",
        "# Move it to the GPU using .to()\n",
        "x1 = x0.to('cuda')\n",
        "print('x1 device:', x1.device)\n",
        "\n",
        "# Move it to the GPU using .cuda()\n",
        "x2 = x0.cuda()\n",
        "print('x2 device:', x2.device)\n",
        "\n",
        "# Move it back to the CPU using .to()\n",
        "x3 = x1.to('cpu')\n",
        "print('x3 device:', x3.device)\n",
        "\n",
        "# Move it back to the CPU using .cpu()\n",
        "x4 = x2.cpu()\n",
        "print('x4 device:', x4.device)\n",
        "\n",
        "# We can construct tensors directly on the GPU as well\n",
        "y = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float64, device='cuda')\n",
        "print('y device / dtype:', y.device, y.dtype)\n",
        "\n",
        "# Calling x.to(y) where y is a tensor will return a copy of x with the same\n",
        "# device and dtype as y\n",
        "x5 = x0.to(y)\n",
        "print('x5 device / dtype:', x5.device, x5.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW14ZF-_PK7t",
        "outputId": "c3665a12-ba2e-42e9-f4f6-68d080d4feac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max difference between c_gpu and c_cpu: 0.0\n",
            "CPU time: 221.75 ms\n",
            "GPU time: 13.07 ms\n",
            "GPU speedup: 16.97 x\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "a_cpu = torch.randn(10000, 10000, dtype=torch.float32)\n",
        "b_cpu = torch.randn(10000, 10000, dtype=torch.float32)\n",
        "\n",
        "a_gpu = a_cpu.cuda()\n",
        "b_gpu = b_cpu.cuda()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "t0 = time.time()\n",
        "c_cpu = a_cpu + b_cpu\n",
        "t1 = time.time()\n",
        "c_gpu = a_gpu + b_gpu\n",
        "torch.cuda.synchronize()\n",
        "t2 = time.time()\n",
        "\n",
        "# Check that they computed the same thing\n",
        "diff = (c_gpu.cpu() - c_cpu).abs().max().item()\n",
        "print('Max difference between c_gpu and c_cpu:', diff)\n",
        "\n",
        "cpu_time = 1000.0 * (t1 - t0)\n",
        "gpu_time = 1000.0 * (t2 - t1)\n",
        "print('CPU time: %.2f ms' % cpu_time)\n",
        "print('GPU time: %.2f ms' % gpu_time)\n",
        "print('GPU speedup: %.2f x' % (cpu_time / gpu_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqEUdst7SAuZ",
        "outputId": "e1fbe90b-dfa4-4abe-e20e-59935f334f31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y1 on CPU: True\n",
            "Max difference between y0 and y1: 0.001220703125\n",
            "Difference within tolerance: True\n",
            "CPU time: 225.47 ms\n",
            "GPU time: 28.70 ms\n",
            "GPU speedup: 7.86 x\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "x = torch.rand(512, 4096)\n",
        "w = torch.rand(4096, 4096)\n",
        "\n",
        "t0 = time.time()\n",
        "y0 = mm_on_cpu(x, w)\n",
        "t1 = time.time()\n",
        "\n",
        "y1 = mm_on_gpu(x, w)\n",
        "torch.cuda.synchronize()\n",
        "t2 = time.time()\n",
        "\n",
        "print('y1 on CPU:', y1.device == torch.device('cpu'))\n",
        "diff = (y0 - y1).abs().max().item()\n",
        "print('Max difference between y0 and y1:', diff)\n",
        "print('Difference within tolerance:', diff < 5e-2)\n",
        "\n",
        "cpu_time = 1000.0 * (t1 - t0)\n",
        "gpu_time = 1000.0 * (t2 - t1)\n",
        "print('CPU time: %.2f ms' % cpu_time)\n",
        "print('GPU time: %.2f ms' % gpu_time)\n",
        "print('GPU speedup: %.2f x' % (cpu_time / gpu_time))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
